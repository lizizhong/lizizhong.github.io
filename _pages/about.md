---
permalink: /
title: "Zizhong Li"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Hello!
I am a second-year CS Ph.D. student at the University of California, Davis, advised by [Dr.Jiawei Zhang](http://jiaweizhang.net). Prior to UC Davis, I received my B.E. degree in Computer Science from Tongji University in Shanghai, China. 

My research interest lies in natural language processing, specifically in nonparametric language modeling, misinformation & information retrieval, and multi-modal generative models. 


Recent Papers
------
[10.2024] **A Survey of AI-Generated Video Evaluation**  [arxiv](https://arxiv.org/pdf/2410.19884)

&emsp; Xiao Liuâˆ—, Xinhao Xiangâˆ—, **Zizhong Liâˆ—**[^1], Yongheng Wang, Zhuoheng Li, Zhuosheng Liu, Weidi Zhang, Weiqi Ye, and Jiawei Zhang

[^1]: Euqal Contribution.

&emsp; In this survey, we identify the emerging field of AI-Generated Video Evaluation (AIGVE), highlighting the importance of assessing how well AI-generated videos align with human perception and meet specific instructions.

[06.2024] **Intermediate Distillation: Data-Efficient Distillation from Black-Box LLMs for Information Retrieval**  [arixv](https://arxiv.org/abs/2406.12169)  [blog page](https://lizizhong.github.io/publication/2024-06-18-paper-intermediate-distillation-number-3)
  
&emsp; **Zizhong Li**, Haopeng Zhang, Jiawei Zhang 

&emsp; In this paper, we introduce a data-efficient knowledge distillation training scheme that treats LLMs as black boxes and distills their knowledge via an innovative LLM ranker-retriever pipeline.

[03.2024] [NAACL2024ðŸŒŸ] **Unveiling the Magic: Investigating Attention Distillation in Retrieval-augmented Generation**  [arxiv](https://arxiv.org/abs/2402.11794)  [blog page](https://lizizhong.github.io/publication/2024-02-19-paper-attention-distillation-number-2)

&emsp; **Zizhong Li**, Haopeng Zhang, Jiawei Zhang

&emsp; In this paper, we address this gap by conducting a comprehensive review of attention distillation workflow and identifying key factors influencing the learning quality of retrieval-augmented language models.




  



